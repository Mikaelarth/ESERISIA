"""
ESERISIA AI - CONTR√îLEUR D'ENTRA√éNEMENT
======================================
Syst√®me de contr√¥le et orchestration des phases d'entra√Ænement
"""

import asyncio
import json
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, asdict
from pathlib import Path
import subprocess
import psutil
import time

@dataclass
class TrainingJob:
    """D√©finition d'un job d'entra√Ænement"""
    id: str
    phase_name: str
    config: Dict[str, Any]
    status: str = "pending"  # pending, running, completed, failed, paused
    start_time: Optional[datetime] = None
    end_time: Optional[datetime] = None
    process_id: Optional[int] = None
    progress: float = 0.0
    current_epoch: int = 0
    metrics: Dict[str, float] = None
    
    def __post_init__(self):
        if self.metrics is None:
            self.metrics = {}

@dataclass
class SystemResources:
    """√âtat des ressources syst√®me"""
    gpu_count: int
    gpu_memory_total: List[int]
    gpu_memory_used: List[int] 
    gpu_utilization: List[float]
    cpu_percent: float
    memory_percent: float
    disk_usage: float
    temperature: float

class EserisiaTrainingController:
    """Contr√¥leur principal d'entra√Ænement ESERISIA"""
    
    def __init__(self, config_path: str = "training_config.json"):
        self.logger = logging.getLogger("ESERISIA_CONTROLLER")
        self.config_path = Path(config_path)
        self.jobs_queue: List[TrainingJob] = []
        self.active_jobs: Dict[str, TrainingJob] = {}
        self.completed_jobs: List[TrainingJob] = []
        
        # Configuration par d√©faut
        self.max_concurrent_jobs = 2
        self.resource_limits = {
            "max_gpu_memory": 95.0,  # %
            "max_temperature": 85.0,  # ¬∞C
            "max_cpu": 90.0,          # %
            "max_memory": 95.0        # %
        }
    
    async def initialize_training_pipeline(self):
        """Initialise le pipeline complet d'entra√Ænement"""
        
        print("üöÄ INITIALISATION PIPELINE D'ENTRA√éNEMENT ESERISIA AI")
        print("=" * 70)
        
        # Chargement du plan d'entra√Ænement
        training_plan = await self._load_training_plan()
        
        if not training_plan:
            print("‚ùå Aucun plan d'entra√Ænement trouv√©!")
            return
        
        # Cr√©ation des jobs d'entra√Ænement
        await self._create_training_jobs(training_plan)
        
        # V√©rification des ressources
        resources = await self._check_system_resources()
        await self._display_resource_status(resources)
        
        # D√©marrage de l'orchestrateur
        await self._start_training_orchestrator()
    
    async def _load_training_plan(self):
        """Charge le plan d'entra√Ænement g√©n√©r√©"""
        
        plan_file = Path("eserisia_training_plan.json")
        
        if not plan_file.exists():
            self.logger.error("Plan d'entra√Ænement non trouv√©")
            return None
        
        try:
            with open(plan_file, 'r', encoding='utf-8') as f:
                plan = json.load(f)
            
            print(f"üìã Plan charg√©: {len(plan.get('training_phases', []))} phases")
            return plan
            
        except Exception as e:
            self.logger.error(f"Erreur chargement plan: {e}")
            return None
    
    async def _create_training_jobs(self, training_plan: Dict[str, Any]):
        """Cr√©e les jobs d'entra√Ænement √† partir du plan"""
        
        phases = training_plan.get("training_phases", [])
        
        print(f"üì¶ Cr√©ation de {len(phases)} jobs d'entra√Ænement:")
        print("-" * 50)
        
        for i, phase in enumerate(phases):
            job_id = f"job_{i+1:02d}_{phase['name'].replace(' ', '_')}"
            
            # Configuration du job
            job_config = {
                "epochs": phase.get("epochs", 10),
                "learning_rate": phase.get("learning_rate", 1e-4),
                "batch_size": phase.get("batch_size", 32),
                "gpu_requirement": phase.get("gpu_requirement", "1x H100"),
                "estimated_duration": phase.get("duration", "24h"),
                "phase_type": phase.get("type", "foundation")
            }
            
            job = TrainingJob(
                id=job_id,
                phase_name=phase["name"],
                config=job_config
            )
            
            self.jobs_queue.append(job)
            
            print(f"   {i+1:2d}. {phase['name']}")
            print(f"       ID: {job_id}")
            print(f"       GPU: {job_config['gpu_requirement']}")
            print(f"       Dur√©e: {job_config['estimated_duration']}")
            print()
    
    async def _check_system_resources(self) -> SystemResources:
        """V√©rifie l'√©tat des ressources syst√®me"""
        
        print("üîç V√âRIFICATION DES RESSOURCES SYST√àME")
        print("-" * 50)
        
        # CPU et m√©moire
        cpu_percent = psutil.cpu_percent(interval=1)
        memory = psutil.virtual_memory()
        disk = psutil.disk_usage('.')
        
        # Simulation GPU (en r√©alit√© il faudrait nvidia-ml-py)
        gpu_count = 8  # Simulation cluster
        gpu_memory_total = [40 * 1024] * gpu_count  # 40GB par GPU
        gpu_memory_used = [int(total * 0.1) for total in gpu_memory_total]  # 10% utilis√©
        gpu_utilization = [5.0] * gpu_count  # 5% utilis√©
        
        # Temp√©rature simul√©e
        temperature = 45.0
        
        resources = SystemResources(
            gpu_count=gpu_count,
            gpu_memory_total=gpu_memory_total,
            gpu_memory_used=gpu_memory_used,
            gpu_utilization=gpu_utilization,
            cpu_percent=cpu_percent,
            memory_percent=memory.percent,
            disk_usage=disk.percent,
            temperature=temperature
        )
        
        return resources
    
    async def _display_resource_status(self, resources: SystemResources):
        """Affiche l'√©tat des ressources"""
        
        print(f"üíª CPU: {resources.cpu_percent:.1f}%")
        print(f"üíæ RAM: {resources.memory_percent:.1f}%")
        print(f"üíø Disque: {resources.disk_usage:.1f}%")
        print(f"üå°Ô∏è Temp√©rature: {resources.temperature:.1f}¬∞C")
        print(f"üéÆ GPUs disponibles: {resources.gpu_count}")
        
        for i, (total, used, util) in enumerate(zip(
            resources.gpu_memory_total, 
            resources.gpu_memory_used, 
            resources.gpu_utilization
        )):
            used_percent = (used / total) * 100
            print(f"   GPU {i}: {util:.1f}% util, {used_percent:.1f}% m√©moire")
        
        print()
        
        # V√©rification des limites
        warnings = []
        
        if resources.cpu_percent > self.resource_limits["max_cpu"]:
            warnings.append(f"‚ö†Ô∏è CPU √©lev√©: {resources.cpu_percent:.1f}%")
        
        if resources.memory_percent > self.resource_limits["max_memory"]:
            warnings.append(f"‚ö†Ô∏è M√©moire √©lev√©e: {resources.memory_percent:.1f}%")
        
        if resources.temperature > self.resource_limits["max_temperature"]:
            warnings.append(f"‚ö†Ô∏è Temp√©rature √©lev√©e: {resources.temperature:.1f}¬∞C")
        
        if warnings:
            print("üö® ALERTES RESSOURCES:")
            for warning in warnings:
                print(f"   {warning}")
            print()
        else:
            print("‚úÖ Toutes les ressources sont dans les limites normales")
            print()
    
    async def _start_training_orchestrator(self):
        """D√©marre l'orchestrateur d'entra√Ænement"""
        
        print("üéØ D√âMARRAGE DE L'ORCHESTRATEUR")
        print("=" * 70)
        
        iteration = 0
        while self.jobs_queue or self.active_jobs:
            iteration += 1
            print(f"\nüìä IT√âRATION {iteration} - {datetime.now().strftime('%H:%M:%S')}")
            print("-" * 50)
            
            # V√©rification des ressources
            resources = await self._check_system_resources()
            
            # Mise √† jour des jobs actifs
            await self._update_active_jobs()
            
            # D√©marrage de nouveaux jobs si possible
            await self._start_pending_jobs(resources)
            
            # Affichage du statut
            await self._display_orchestrator_status()
            
            # Attente avant prochaine it√©ration
            await asyncio.sleep(5)
        
        print("\nüéâ TOUS LES JOBS D'ENTRA√éNEMENT TERMIN√âS!")
        await self._generate_final_summary()
    
    async def _update_active_jobs(self):
        """Met √† jour l'√©tat des jobs actifs"""
        
        completed_job_ids = []
        
        for job_id, job in self.active_jobs.items():
            
            # Simulation de progression
            if job.status == "running":
                job.progress += 10.0  # 10% par it√©ration
                job.current_epoch += 1
                
                # M√©triques simul√©es
                job.metrics.update({
                    "loss": max(0.1, 4.0 * (1 - job.progress/100)),
                    "accuracy": min(99.9, 85 + job.progress/100 * 14),
                    "gpu_util": 95.0,
                    "throughput": 4500 + job.progress * 10
                })
                
                # Job termin√© √† 100%
                if job.progress >= 100.0:
                    job.status = "completed"
                    job.end_time = datetime.now()
                    job.progress = 100.0
                    completed_job_ids.append(job_id)
        
        # D√©placement des jobs termin√©s
        for job_id in completed_job_ids:
            completed_job = self.active_jobs.pop(job_id)
            self.completed_jobs.append(completed_job)
            
            print(f"‚úÖ Job termin√©: {completed_job.phase_name}")
    
    async def _start_pending_jobs(self, resources: SystemResources):
        """D√©marre de nouveaux jobs si les ressources le permettent"""
        
        # V√©rification disponibilit√©
        can_start = (
            len(self.active_jobs) < self.max_concurrent_jobs and 
            self.jobs_queue and
            resources.cpu_percent < self.resource_limits["max_cpu"] and
            resources.memory_percent < self.resource_limits["max_memory"]
        )
        
        if not can_start:
            return
        
        # D√©marrage du prochain job
        job = self.jobs_queue.pop(0)
        job.status = "running"
        job.start_time = datetime.now()
        job.process_id = 12345  # Simulation
        
        self.active_jobs[job.id] = job
        
        print(f"üöÄ D√©marrage job: {job.phase_name}")
        print(f"   Config: {job.config['epochs']} epochs, {job.config['learning_rate']} LR")
    
    async def _display_orchestrator_status(self):
        """Affiche le statut de l'orchestrateur"""
        
        print(f"üìà STATUT:")
        print(f"   En attente: {len(self.jobs_queue)}")
        print(f"   En cours: {len(self.active_jobs)}")
        print(f"   Termin√©s: {len(self.completed_jobs)}")
        
        if self.active_jobs:
            print(f"üîÑ JOBS ACTIFS:")
            for job in self.active_jobs.values():
                print(f"   {job.phase_name}: {job.progress:.1f}% - √âpoque {job.current_epoch}")
                if job.metrics:
                    print(f"      Loss: {job.metrics.get('loss', 0):.3f}, "
                          f"Acc: {job.metrics.get('accuracy', 0):.1f}%")
    
    async def _generate_final_summary(self):
        """G√©n√®re le r√©sum√© final"""
        
        print("üìä R√âSUM√â FINAL D'ENTRA√éNEMENT")
        print("=" * 70)
        
        total_duration = timedelta()
        
        for job in self.completed_jobs:
            if job.start_time and job.end_time:
                duration = job.end_time - job.start_time
                total_duration += duration
                
                print(f"‚úÖ {job.phase_name}")
                print(f"   Dur√©e: {duration}")
                print(f"   M√©triques finales: {job.metrics}")
                print()
        
        print(f"‚è±Ô∏è Dur√©e totale: {total_duration}")
        print(f"üéØ Jobs termin√©s: {len(self.completed_jobs)}")
        
        # Sauvegarde du rapport
        report = {
            "summary": {
                "total_jobs": len(self.completed_jobs),
                "total_duration": str(total_duration),
                "completion_time": datetime.now().isoformat()
            },
            "completed_jobs": [
                {
                    "id": job.id,
                    "phase_name": job.phase_name,
                    "duration": str(job.end_time - job.start_time) if job.start_time and job.end_time else None,
                    "final_metrics": job.metrics
                }
                for job in self.completed_jobs
            ]
        }
        
        with open("training_execution_report.json", 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print("üìÑ Rapport sauvegard√©: training_execution_report.json")

async def main():
    """Point d'entr√©e principal"""
    
    controller = EserisiaTrainingController()
    await controller.initialize_training_pipeline()

if __name__ == "__main__":
    print("üéõÔ∏è ESERISIA AI - CONTR√îLEUR D'ENTRA√éNEMENT")
    print("=" * 60)
    
    asyncio.run(main())
